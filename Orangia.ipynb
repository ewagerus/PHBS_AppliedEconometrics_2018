{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UPLOADING LIBRARIES, PACKAGES AND DATAFILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* GENERAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* PLOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt   \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.stats.api as sms\n",
    "from statsmodels.compat import lzip\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* READING DATAFILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('odot.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.Ratio=df.Price/df.FairPr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>FairPr</th>\n",
       "      <th>Ratio</th>\n",
       "      <th>Bidders</th>\n",
       "      <th>Rigged</th>\n",
       "      <th>Length</th>\n",
       "      <th>FxCost</th>\n",
       "      <th>Days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>133.000000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>133.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>985.541353</td>\n",
       "      <td>1059.533835</td>\n",
       "      <td>0.950344</td>\n",
       "      <td>5.150376</td>\n",
       "      <td>0.270677</td>\n",
       "      <td>4.542857</td>\n",
       "      <td>516.429639</td>\n",
       "      <td>185.150376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1494.291210</td>\n",
       "      <td>1628.365678</td>\n",
       "      <td>0.143738</td>\n",
       "      <td>2.880173</td>\n",
       "      <td>0.445989</td>\n",
       "      <td>4.627966</td>\n",
       "      <td>1012.171017</td>\n",
       "      <td>173.985087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.564278</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>167.000000</td>\n",
       "      <td>174.000000</td>\n",
       "      <td>0.846491</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>26.268000</td>\n",
       "      <td>75.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>431.000000</td>\n",
       "      <td>435.000000</td>\n",
       "      <td>0.945107</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>89.880000</td>\n",
       "      <td>125.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>924.000000</td>\n",
       "      <td>970.000000</td>\n",
       "      <td>1.045455</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>378.219000</td>\n",
       "      <td>210.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9453.000000</td>\n",
       "      <td>9480.000000</td>\n",
       "      <td>1.304598</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>6086.160000</td>\n",
       "      <td>900.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Price       FairPr       Ratio     Bidders      Rigged  \\\n",
       "count   133.000000   133.000000  133.000000  133.000000  133.000000   \n",
       "mean    985.541353  1059.533835    0.950344    5.150376    0.270677   \n",
       "std    1494.291210  1628.365678    0.143738    2.880173    0.445989   \n",
       "min      23.000000    22.000000    0.564278    1.000000    0.000000   \n",
       "25%     167.000000   174.000000    0.846491    3.000000    0.000000   \n",
       "50%     431.000000   435.000000    0.945107    4.000000    0.000000   \n",
       "75%     924.000000   970.000000    1.045455    7.000000    1.000000   \n",
       "max    9453.000000  9480.000000    1.304598   13.000000    1.000000   \n",
       "\n",
       "           Length       FxCost        Days  \n",
       "count  133.000000   133.000000  133.000000  \n",
       "mean     4.542857   516.429639  185.150376  \n",
       "std      4.627966  1012.171017  173.985087  \n",
       "min      0.100000     1.200000   30.000000  \n",
       "25%      1.400000    26.268000   75.000000  \n",
       "50%      3.100000    89.880000  125.000000  \n",
       "75%      6.200000   378.219000  210.000000  \n",
       "max     23.500000  6086.160000  900.000000  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* CORRELATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#correlation matrix\n",
    "X = df[['FairPr', 'Bidders', 'Rigged', 'Length', 'FxCost', 'Days']]\n",
    "f, ax = plt.subplots(figsize=(15, 15))\n",
    "corr = X.corr()\n",
    "sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
    "            square=True, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* FITTING A REGRESSION MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  Ratio   R-squared:                       0.424\n",
      "Model:                            OLS   Adj. R-squared:                  0.397\n",
      "Method:                 Least Squares   F-statistic:                     15.48\n",
      "Date:                Mon, 14 Jan 2019   Prob (F-statistic):           3.04e-13\n",
      "Time:                        16:04:06   Log-Likelihood:                 106.50\n",
      "No. Observations:                 133   AIC:                            -199.0\n",
      "Df Residuals:                     126   BIC:                            -178.8\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.9192      0.029     31.638      0.000       0.862       0.977\n",
      "FairPr     -4.811e-05   4.42e-05     -1.089      0.278      -0.000    3.93e-05\n",
      "Bidders       -0.0075      0.004     -1.876      0.063      -0.015       0.000\n",
      "Rigged         0.1832      0.025      7.341      0.000       0.134       0.233\n",
      "Length         0.0009      0.002      0.379      0.705      -0.004       0.006\n",
      "FxCost        5.5e-05   6.27e-05      0.877      0.382   -6.92e-05       0.000\n",
      "Days           0.0002      0.000      1.703      0.091   -3.37e-05       0.000\n",
      "==============================================================================\n",
      "Omnibus:                        0.234   Durbin-Watson:                   1.642\n",
      "Prob(Omnibus):                  0.890   Jarque-Bera (JB):                0.405\n",
      "Skew:                          -0.023   Prob(JB):                        0.817\n",
      "Kurtosis:                       2.733   Cond. No.                     7.79e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 7.79e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "results = smf.ols('Ratio ~ FairPr + Bidders + Rigged + Length + FxCost + Days', data=df).fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>0.871067</td>\n",
       "      <td>0.967355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FairPr</th>\n",
       "      <td>-0.000121</td>\n",
       "      <td>0.000025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bidders</th>\n",
       "      <td>-0.014133</td>\n",
       "      <td>-0.000876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rigged</th>\n",
       "      <td>0.141865</td>\n",
       "      <td>0.224587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Length</th>\n",
       "      <td>-0.003195</td>\n",
       "      <td>0.005088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FxCost</th>\n",
       "      <td>-0.000049</td>\n",
       "      <td>0.000159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Days</th>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0         1\n",
       "Intercept  0.871067  0.967355\n",
       "FairPr    -0.000121  0.000025\n",
       "Bidders   -0.014133 -0.000876\n",
       "Rigged     0.141865  0.224587\n",
       "Length    -0.003195  0.005088\n",
       "FxCost    -0.000049  0.000159\n",
       "Days       0.000006  0.000410"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.conf_int(alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* MULTICOLLINEARITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('FairPr', 77.30138244893712),\n",
       " ('Bidders', 2.586880559860412),\n",
       " ('Rigged', 1.3403498715266824),\n",
       " ('Length', 2.5203119782872654),\n",
       " ('FxCost', 53.90230996264113),\n",
       " ('Days', 9.11122708185233)]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vif = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "lzip(X.columns, vif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* FUNCTIONAL FORM OF A MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# source: https://www.statsmodels.org/dev/_modules/statsmodels/stats/outliers_influence.html\n",
    "def reset_ramsey(res, degree=5):\n",
    "    '''Ramsey's RESET specification test for linear models\n",
    "\n",
    "    This is a general specification test, for additional non-linear effects\n",
    "    in a model.\n",
    "\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The test fits an auxiliary OLS regression where the design matrix, exog,\n",
    "    is augmented by powers 2 to degree of the fitted values. Then it performs\n",
    "    an F-test whether these additional terms are significant.\n",
    "\n",
    "    If the p-value of the f-test is below a threshold, e.g. 0.1, then this\n",
    "    indicates that there might be additional non-linear effects in the model\n",
    "    and that the linear model is mis-specified.\n",
    "\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    http://en.wikipedia.org/wiki/Ramsey_RESET_test\n",
    "\n",
    "    '''\n",
    "    order = degree + 1\n",
    "    k_vars = res.model.exog.shape[1]\n",
    "    #vander without constant and x:\n",
    "    y_fitted_vander = np.vander(res.fittedvalues, order)[:, :-2] #drop constant\n",
    "    exog = np.column_stack((res.model.exog, y_fitted_vander))\n",
    "    res_aux = OLS(res.model.endog, exog).fit()\n",
    "    #r_matrix = np.eye(degree, exog.shape[1], k_vars)\n",
    "    r_matrix = np.eye(degree-1, exog.shape[1], k_vars)\n",
    "    #df1 = degree - 1\n",
    "    #df2 = exog.shape[0] - degree - res.df_model  (without constant)\n",
    "    return res_aux.f_test(r_matrix) #, r_matrix, res_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'statsmodels.stats.contrast.ContrastResults'>\n",
       "<F test: F=array([[0.47498008]]), p=0.7540258334875081, df_denom=122, df_num=4>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = ['t value', 'p value']\n",
    "test = reset_ramsey(results)\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ramsey RESET Test\n",
    "<br> H_0: correct specification of the model\n",
    "<br> H_1: the model suffers from misspecification\n",
    "<br> RESET = 0.754 > 0.05 => no reason to reject null hyphothesis\n",
    "<br> The functional form of a model is correctly specified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* NORMALITY OF THE RESIDUALS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jarque-Bera Test\n",
    "<br> H_0: residuals have a normal distribution\n",
    "<br> H_1: residuals do not have a normal distribution\n",
    "<br> JB = 0.817 > 0.05 => no reason to reject null hyphothesis\n",
    "<br> Residuals have a normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* HETEROSKEDASTICITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Lagrange multiplier statistic', 4.284121414130722),\n",
       " ('p-value', 0.6382871372608576),\n",
       " ('f-value', 0.6989545554531295),\n",
       " ('f p-value', 0.6509261255146672)]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = ['Lagrange multiplier statistic', 'p-value',\n",
    "        'f-value', 'f p-value']\n",
    "test = sms.het_breuschpagan(results.resid, results.model.exog)\n",
    "lzip(name, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Breush-Pagan test\n",
    "<br> H_0: homoskedasticity\n",
    "<br> H_1: heteroskedasticity\n",
    "BP = 0.638 > 0.05 => no reason to reject null hyphothesis\n",
    "<br> The problem of heteroskedasticity does not occure in this model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### (i) Give your best estimate and a 90% confidence interval of what will happen to the ratio of the actual price to the estimated cost if the number of days for a project decreases by 250, holding the other independent variables fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean_se</th>\n",
       "      <th>mean_ci_lower</th>\n",
       "      <th>mean_ci_upper</th>\n",
       "      <th>obs_ci_lower</th>\n",
       "      <th>obs_ci_upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.879318</td>\n",
       "      <td>0.019444</td>\n",
       "      <td>0.840839</td>\n",
       "      <td>0.917796</td>\n",
       "      <td>0.655092</td>\n",
       "      <td>1.103543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.872160</td>\n",
       "      <td>0.019413</td>\n",
       "      <td>0.833742</td>\n",
       "      <td>0.910578</td>\n",
       "      <td>0.647945</td>\n",
       "      <td>1.096375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.088919</td>\n",
       "      <td>0.022794</td>\n",
       "      <td>1.043810</td>\n",
       "      <td>1.134029</td>\n",
       "      <td>0.863462</td>\n",
       "      <td>1.314377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.100298</td>\n",
       "      <td>0.022764</td>\n",
       "      <td>1.055248</td>\n",
       "      <td>1.145348</td>\n",
       "      <td>0.874852</td>\n",
       "      <td>1.325744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.913104</td>\n",
       "      <td>0.018568</td>\n",
       "      <td>0.876357</td>\n",
       "      <td>0.949850</td>\n",
       "      <td>0.689169</td>\n",
       "      <td>1.137038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.913041</td>\n",
       "      <td>0.021799</td>\n",
       "      <td>0.869901</td>\n",
       "      <td>0.956182</td>\n",
       "      <td>0.687969</td>\n",
       "      <td>1.138113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.081932</td>\n",
       "      <td>0.023101</td>\n",
       "      <td>1.036216</td>\n",
       "      <td>1.127648</td>\n",
       "      <td>0.856352</td>\n",
       "      <td>1.307512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.922460</td>\n",
       "      <td>0.019325</td>\n",
       "      <td>0.884216</td>\n",
       "      <td>0.960704</td>\n",
       "      <td>0.698275</td>\n",
       "      <td>1.146645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.910005</td>\n",
       "      <td>0.018754</td>\n",
       "      <td>0.872893</td>\n",
       "      <td>0.947118</td>\n",
       "      <td>0.686010</td>\n",
       "      <td>1.134000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.878486</td>\n",
       "      <td>0.017282</td>\n",
       "      <td>0.844287</td>\n",
       "      <td>0.912686</td>\n",
       "      <td>0.654956</td>\n",
       "      <td>1.102017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.090880</td>\n",
       "      <td>0.022575</td>\n",
       "      <td>1.046204</td>\n",
       "      <td>1.135555</td>\n",
       "      <td>0.865508</td>\n",
       "      <td>1.316251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.107108</td>\n",
       "      <td>0.024921</td>\n",
       "      <td>1.057790</td>\n",
       "      <td>1.156426</td>\n",
       "      <td>0.880771</td>\n",
       "      <td>1.333445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.888275</td>\n",
       "      <td>0.016447</td>\n",
       "      <td>0.855728</td>\n",
       "      <td>0.920823</td>\n",
       "      <td>0.664991</td>\n",
       "      <td>1.111559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.913606</td>\n",
       "      <td>0.021306</td>\n",
       "      <td>0.871443</td>\n",
       "      <td>0.955769</td>\n",
       "      <td>0.688719</td>\n",
       "      <td>1.138493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.905122</td>\n",
       "      <td>0.019219</td>\n",
       "      <td>0.867089</td>\n",
       "      <td>0.943155</td>\n",
       "      <td>0.680973</td>\n",
       "      <td>1.129271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.914012</td>\n",
       "      <td>0.018257</td>\n",
       "      <td>0.877882</td>\n",
       "      <td>0.950141</td>\n",
       "      <td>0.690178</td>\n",
       "      <td>1.137846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.904749</td>\n",
       "      <td>0.019120</td>\n",
       "      <td>0.866910</td>\n",
       "      <td>0.942587</td>\n",
       "      <td>0.680632</td>\n",
       "      <td>1.128865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.120302</td>\n",
       "      <td>0.031190</td>\n",
       "      <td>1.058578</td>\n",
       "      <td>1.182026</td>\n",
       "      <td>0.890942</td>\n",
       "      <td>1.349662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.880431</td>\n",
       "      <td>0.016970</td>\n",
       "      <td>0.846848</td>\n",
       "      <td>0.914013</td>\n",
       "      <td>0.656993</td>\n",
       "      <td>1.103868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.865701</td>\n",
       "      <td>0.025226</td>\n",
       "      <td>0.815780</td>\n",
       "      <td>0.915622</td>\n",
       "      <td>0.639232</td>\n",
       "      <td>1.092171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.898126</td>\n",
       "      <td>0.017053</td>\n",
       "      <td>0.864378</td>\n",
       "      <td>0.931873</td>\n",
       "      <td>0.674664</td>\n",
       "      <td>1.121588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.909081</td>\n",
       "      <td>0.018651</td>\n",
       "      <td>0.872171</td>\n",
       "      <td>0.945992</td>\n",
       "      <td>0.685120</td>\n",
       "      <td>1.133043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.890896</td>\n",
       "      <td>0.015576</td>\n",
       "      <td>0.860072</td>\n",
       "      <td>0.921720</td>\n",
       "      <td>0.667857</td>\n",
       "      <td>1.113935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.841387</td>\n",
       "      <td>0.031438</td>\n",
       "      <td>0.779172</td>\n",
       "      <td>0.903601</td>\n",
       "      <td>0.611894</td>\n",
       "      <td>1.070880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.911141</td>\n",
       "      <td>0.015232</td>\n",
       "      <td>0.880998</td>\n",
       "      <td>0.941284</td>\n",
       "      <td>0.688195</td>\n",
       "      <td>1.134087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.101472</td>\n",
       "      <td>0.021837</td>\n",
       "      <td>1.058258</td>\n",
       "      <td>1.144686</td>\n",
       "      <td>0.876386</td>\n",
       "      <td>1.326558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.123629</td>\n",
       "      <td>0.047370</td>\n",
       "      <td>1.029885</td>\n",
       "      <td>1.217373</td>\n",
       "      <td>0.883662</td>\n",
       "      <td>1.363596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.892889</td>\n",
       "      <td>0.015186</td>\n",
       "      <td>0.862835</td>\n",
       "      <td>0.922943</td>\n",
       "      <td>0.669955</td>\n",
       "      <td>1.115823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.103096</td>\n",
       "      <td>0.021659</td>\n",
       "      <td>1.060233</td>\n",
       "      <td>1.145959</td>\n",
       "      <td>0.878077</td>\n",
       "      <td>1.328115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.097238</td>\n",
       "      <td>0.021297</td>\n",
       "      <td>1.055092</td>\n",
       "      <td>1.139383</td>\n",
       "      <td>0.872354</td>\n",
       "      <td>1.322121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>1.091497</td>\n",
       "      <td>0.019141</td>\n",
       "      <td>1.053618</td>\n",
       "      <td>1.129376</td>\n",
       "      <td>0.867374</td>\n",
       "      <td>1.315620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.883804</td>\n",
       "      <td>0.013616</td>\n",
       "      <td>0.856859</td>\n",
       "      <td>0.910750</td>\n",
       "      <td>0.661268</td>\n",
       "      <td>1.106341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.881905</td>\n",
       "      <td>0.014860</td>\n",
       "      <td>0.852498</td>\n",
       "      <td>0.911313</td>\n",
       "      <td>0.659057</td>\n",
       "      <td>1.104753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.912509</td>\n",
       "      <td>0.017935</td>\n",
       "      <td>0.877016</td>\n",
       "      <td>0.948001</td>\n",
       "      <td>0.688776</td>\n",
       "      <td>1.136241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>1.098124</td>\n",
       "      <td>0.022204</td>\n",
       "      <td>1.054184</td>\n",
       "      <td>1.142065</td>\n",
       "      <td>0.872897</td>\n",
       "      <td>1.323351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.892188</td>\n",
       "      <td>0.016325</td>\n",
       "      <td>0.859882</td>\n",
       "      <td>0.924495</td>\n",
       "      <td>0.668939</td>\n",
       "      <td>1.115437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>1.095260</td>\n",
       "      <td>0.022521</td>\n",
       "      <td>1.050692</td>\n",
       "      <td>1.139828</td>\n",
       "      <td>0.869910</td>\n",
       "      <td>1.320610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>1.123073</td>\n",
       "      <td>0.021411</td>\n",
       "      <td>1.080701</td>\n",
       "      <td>1.165444</td>\n",
       "      <td>0.898147</td>\n",
       "      <td>1.347999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>1.101689</td>\n",
       "      <td>0.020009</td>\n",
       "      <td>1.062091</td>\n",
       "      <td>1.141286</td>\n",
       "      <td>0.877269</td>\n",
       "      <td>1.326109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>1.093286</td>\n",
       "      <td>0.020460</td>\n",
       "      <td>1.052797</td>\n",
       "      <td>1.133775</td>\n",
       "      <td>0.868707</td>\n",
       "      <td>1.317865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>1.089208</td>\n",
       "      <td>0.021670</td>\n",
       "      <td>1.046325</td>\n",
       "      <td>1.132092</td>\n",
       "      <td>0.864185</td>\n",
       "      <td>1.314231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.913357</td>\n",
       "      <td>0.023321</td>\n",
       "      <td>0.867206</td>\n",
       "      <td>0.959509</td>\n",
       "      <td>0.687689</td>\n",
       "      <td>1.139026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.920089</td>\n",
       "      <td>0.020827</td>\n",
       "      <td>0.878873</td>\n",
       "      <td>0.961305</td>\n",
       "      <td>0.695378</td>\n",
       "      <td>1.144801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>1.098460</td>\n",
       "      <td>0.020585</td>\n",
       "      <td>1.057722</td>\n",
       "      <td>1.139197</td>\n",
       "      <td>0.873836</td>\n",
       "      <td>1.323084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>1.107429</td>\n",
       "      <td>0.022408</td>\n",
       "      <td>1.063084</td>\n",
       "      <td>1.151773</td>\n",
       "      <td>0.882123</td>\n",
       "      <td>1.332735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.869567</td>\n",
       "      <td>0.021337</td>\n",
       "      <td>0.827343</td>\n",
       "      <td>0.911792</td>\n",
       "      <td>0.644669</td>\n",
       "      <td>1.094466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.879937</td>\n",
       "      <td>0.019334</td>\n",
       "      <td>0.841676</td>\n",
       "      <td>0.918199</td>\n",
       "      <td>0.655749</td>\n",
       "      <td>1.104125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>1.095630</td>\n",
       "      <td>0.024007</td>\n",
       "      <td>1.048121</td>\n",
       "      <td>1.143139</td>\n",
       "      <td>0.869680</td>\n",
       "      <td>1.321580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>1.101484</td>\n",
       "      <td>0.025559</td>\n",
       "      <td>1.050904</td>\n",
       "      <td>1.152065</td>\n",
       "      <td>0.874868</td>\n",
       "      <td>1.328100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.910810</td>\n",
       "      <td>0.020287</td>\n",
       "      <td>0.870663</td>\n",
       "      <td>0.950958</td>\n",
       "      <td>0.686292</td>\n",
       "      <td>1.135328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.887286</td>\n",
       "      <td>0.027946</td>\n",
       "      <td>0.831982</td>\n",
       "      <td>0.942591</td>\n",
       "      <td>0.659569</td>\n",
       "      <td>1.115003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.920208</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>0.848965</td>\n",
       "      <td>0.991452</td>\n",
       "      <td>0.688105</td>\n",
       "      <td>1.152312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.908877</td>\n",
       "      <td>0.026382</td>\n",
       "      <td>0.856668</td>\n",
       "      <td>0.961086</td>\n",
       "      <td>0.681892</td>\n",
       "      <td>1.135862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>1.101968</td>\n",
       "      <td>0.028092</td>\n",
       "      <td>1.046374</td>\n",
       "      <td>1.157562</td>\n",
       "      <td>0.874180</td>\n",
       "      <td>1.329755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>1.101708</td>\n",
       "      <td>0.029715</td>\n",
       "      <td>1.042904</td>\n",
       "      <td>1.160513</td>\n",
       "      <td>0.873116</td>\n",
       "      <td>1.330301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.905135</td>\n",
       "      <td>0.035440</td>\n",
       "      <td>0.835000</td>\n",
       "      <td>0.975270</td>\n",
       "      <td>0.673370</td>\n",
       "      <td>1.136901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>1.090852</td>\n",
       "      <td>0.032709</td>\n",
       "      <td>1.026121</td>\n",
       "      <td>1.155582</td>\n",
       "      <td>0.860664</td>\n",
       "      <td>1.321039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.894604</td>\n",
       "      <td>0.038106</td>\n",
       "      <td>0.819192</td>\n",
       "      <td>0.970015</td>\n",
       "      <td>0.661187</td>\n",
       "      <td>1.128020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.875837</td>\n",
       "      <td>0.041062</td>\n",
       "      <td>0.794576</td>\n",
       "      <td>0.957099</td>\n",
       "      <td>0.640466</td>\n",
       "      <td>1.111209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>1.094861</td>\n",
       "      <td>0.042368</td>\n",
       "      <td>1.011016</td>\n",
       "      <td>1.178707</td>\n",
       "      <td>0.858585</td>\n",
       "      <td>1.331137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>133 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         mean   mean_se  mean_ci_lower  mean_ci_upper  obs_ci_lower  \\\n",
       "0    0.879318  0.019444       0.840839       0.917796      0.655092   \n",
       "1    0.872160  0.019413       0.833742       0.910578      0.647945   \n",
       "2    1.088919  0.022794       1.043810       1.134029      0.863462   \n",
       "3    1.100298  0.022764       1.055248       1.145348      0.874852   \n",
       "4    0.913104  0.018568       0.876357       0.949850      0.689169   \n",
       "5    0.913041  0.021799       0.869901       0.956182      0.687969   \n",
       "6    1.081932  0.023101       1.036216       1.127648      0.856352   \n",
       "7    0.922460  0.019325       0.884216       0.960704      0.698275   \n",
       "8    0.910005  0.018754       0.872893       0.947118      0.686010   \n",
       "9    0.878486  0.017282       0.844287       0.912686      0.654956   \n",
       "10   1.090880  0.022575       1.046204       1.135555      0.865508   \n",
       "11   1.107108  0.024921       1.057790       1.156426      0.880771   \n",
       "12   0.888275  0.016447       0.855728       0.920823      0.664991   \n",
       "13   0.913606  0.021306       0.871443       0.955769      0.688719   \n",
       "14   0.905122  0.019219       0.867089       0.943155      0.680973   \n",
       "15   0.914012  0.018257       0.877882       0.950141      0.690178   \n",
       "16   0.904749  0.019120       0.866910       0.942587      0.680632   \n",
       "17   1.120302  0.031190       1.058578       1.182026      0.890942   \n",
       "18   0.880431  0.016970       0.846848       0.914013      0.656993   \n",
       "19   0.865701  0.025226       0.815780       0.915622      0.639232   \n",
       "20   0.898126  0.017053       0.864378       0.931873      0.674664   \n",
       "21   0.909081  0.018651       0.872171       0.945992      0.685120   \n",
       "22   0.890896  0.015576       0.860072       0.921720      0.667857   \n",
       "23   0.841387  0.031438       0.779172       0.903601      0.611894   \n",
       "24   0.911141  0.015232       0.880998       0.941284      0.688195   \n",
       "25   1.101472  0.021837       1.058258       1.144686      0.876386   \n",
       "26   1.123629  0.047370       1.029885       1.217373      0.883662   \n",
       "27   0.892889  0.015186       0.862835       0.922943      0.669955   \n",
       "28   1.103096  0.021659       1.060233       1.145959      0.878077   \n",
       "29   1.097238  0.021297       1.055092       1.139383      0.872354   \n",
       "..        ...       ...            ...            ...           ...   \n",
       "103  1.091497  0.019141       1.053618       1.129376      0.867374   \n",
       "104  0.883804  0.013616       0.856859       0.910750      0.661268   \n",
       "105  0.881905  0.014860       0.852498       0.911313      0.659057   \n",
       "106  0.912509  0.017935       0.877016       0.948001      0.688776   \n",
       "107  1.098124  0.022204       1.054184       1.142065      0.872897   \n",
       "108  0.892188  0.016325       0.859882       0.924495      0.668939   \n",
       "109  1.095260  0.022521       1.050692       1.139828      0.869910   \n",
       "110  1.123073  0.021411       1.080701       1.165444      0.898147   \n",
       "111  1.101689  0.020009       1.062091       1.141286      0.877269   \n",
       "112  1.093286  0.020460       1.052797       1.133775      0.868707   \n",
       "113  1.089208  0.021670       1.046325       1.132092      0.864185   \n",
       "114  0.913357  0.023321       0.867206       0.959509      0.687689   \n",
       "115  0.920089  0.020827       0.878873       0.961305      0.695378   \n",
       "116  1.098460  0.020585       1.057722       1.139197      0.873836   \n",
       "117  1.107429  0.022408       1.063084       1.151773      0.882123   \n",
       "118  0.869567  0.021337       0.827343       0.911792      0.644669   \n",
       "119  0.879937  0.019334       0.841676       0.918199      0.655749   \n",
       "120  1.095630  0.024007       1.048121       1.143139      0.869680   \n",
       "121  1.101484  0.025559       1.050904       1.152065      0.874868   \n",
       "122  0.910810  0.020287       0.870663       0.950958      0.686292   \n",
       "123  0.887286  0.027946       0.831982       0.942591      0.659569   \n",
       "124  0.920208  0.036000       0.848965       0.991452      0.688105   \n",
       "125  0.908877  0.026382       0.856668       0.961086      0.681892   \n",
       "126  1.101968  0.028092       1.046374       1.157562      0.874180   \n",
       "127  1.101708  0.029715       1.042904       1.160513      0.873116   \n",
       "128  0.905135  0.035440       0.835000       0.975270      0.673370   \n",
       "129  1.090852  0.032709       1.026121       1.155582      0.860664   \n",
       "130  0.894604  0.038106       0.819192       0.970015      0.661187   \n",
       "131  0.875837  0.041062       0.794576       0.957099      0.640466   \n",
       "132  1.094861  0.042368       1.011016       1.178707      0.858585   \n",
       "\n",
       "     obs_ci_upper  \n",
       "0        1.103543  \n",
       "1        1.096375  \n",
       "2        1.314377  \n",
       "3        1.325744  \n",
       "4        1.137038  \n",
       "5        1.138113  \n",
       "6        1.307512  \n",
       "7        1.146645  \n",
       "8        1.134000  \n",
       "9        1.102017  \n",
       "10       1.316251  \n",
       "11       1.333445  \n",
       "12       1.111559  \n",
       "13       1.138493  \n",
       "14       1.129271  \n",
       "15       1.137846  \n",
       "16       1.128865  \n",
       "17       1.349662  \n",
       "18       1.103868  \n",
       "19       1.092171  \n",
       "20       1.121588  \n",
       "21       1.133043  \n",
       "22       1.113935  \n",
       "23       1.070880  \n",
       "24       1.134087  \n",
       "25       1.326558  \n",
       "26       1.363596  \n",
       "27       1.115823  \n",
       "28       1.328115  \n",
       "29       1.322121  \n",
       "..            ...  \n",
       "103      1.315620  \n",
       "104      1.106341  \n",
       "105      1.104753  \n",
       "106      1.136241  \n",
       "107      1.323351  \n",
       "108      1.115437  \n",
       "109      1.320610  \n",
       "110      1.347999  \n",
       "111      1.326109  \n",
       "112      1.317865  \n",
       "113      1.314231  \n",
       "114      1.139026  \n",
       "115      1.144801  \n",
       "116      1.323084  \n",
       "117      1.332735  \n",
       "118      1.094466  \n",
       "119      1.104125  \n",
       "120      1.321580  \n",
       "121      1.328100  \n",
       "122      1.135328  \n",
       "123      1.115003  \n",
       "124      1.152312  \n",
       "125      1.135862  \n",
       "126      1.329755  \n",
       "127      1.330301  \n",
       "128      1.136901  \n",
       "129      1.321039  \n",
       "130      1.128020  \n",
       "131      1.111209  \n",
       "132      1.331137  \n",
       "\n",
       "[133 rows x 6 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "days_change = - 250\n",
    "\n",
    "mean = results.params.loc['Days'] * days_change\n",
    "interval = results.conf_int(alpha=0.1).loc['Days'] * days_change\n",
    "\n",
    "pred = lzip(['Mean', '10% Lower Bound', '10% Upper Bound'], [mean, interval[0], interval[1]])\n",
    "pred\n",
    "a= results.get_prediction()\n",
    "a.summary_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (ii) Can you claim at the usual 5% significance level that an increase in the number of bidders, holding the other independent variables fixed, will on average decrease the ratio of the price of a project relative to the ODOT estimate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing table \"OLS Regression Results\" and values of P>|t| for each coefficient, assuming 5% level of significance, we are not in a position to claim that increasing the number of bidders will decrease the ratio. (p-value of Bidders: 0.063 > 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iii) Would it be legitimate, at the usual 5% significance level, to drop the variables FairPr and FxCost out of the regression, if you wanted to do so? If the answer is yes, write down the new estimated regression equation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing table \"OLS Regression Results\" and values of P>|t| for each coefficient, assuming 5% level of significance, we are in a position to claim that variables FairPr and FxCost are not statistically significant so we can drop the out of the regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  Ratio   R-squared:                       0.417\n",
      "Model:                            OLS   Adj. R-squared:                  0.399\n",
      "Method:                 Least Squares   F-statistic:                     22.91\n",
      "Date:                Mon, 14 Jan 2019   Prob (F-statistic):           2.73e-14\n",
      "Time:                        14:46:29   Log-Likelihood:                 105.68\n",
      "No. Observations:                 133   AIC:                            -201.4\n",
      "Df Residuals:                     128   BIC:                            -186.9\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.9273      0.028     33.396      0.000       0.872       0.982\n",
      "Bidders       -0.0080      0.004     -2.022      0.045      -0.016      -0.000\n",
      "Rigged         0.1849      0.025      7.477      0.000       0.136       0.234\n",
      "Length        -0.0002      0.002     -0.115      0.909      -0.004       0.004\n",
      "Days        8.277e-05   5.89e-05      1.405      0.163   -3.38e-05       0.000\n",
      "==============================================================================\n",
      "Omnibus:                        0.127   Durbin-Watson:                   1.630\n",
      "Prob(Omnibus):                  0.939   Jarque-Bera (JB):                0.266\n",
      "Skew:                          -0.054   Prob(JB):                        0.875\n",
      "Kurtosis:                       2.809   Cond. No.                         858.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "results1 = smf.ols('Ratio ~ Bidders + Rigged + Length + Days', data=df).fit()\n",
    "print(results1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(iv) One of your colleagues, Stan, draws your attention to a potential problem in the regression. He claims, Almost all of the jobs the attorney general classified as rigged took place during the hot summer months. Everyone knows that jobs in the hot weather are harder to do, and therefore command a greater premium over estimated costs than jobs done at other times of the year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) If Stan is right then what is wrong with the regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Suppose you can gather data regarding the time of year each job took place and use it to create a new variable, HOT (= 1 if the job took place during the hot summer months and = 0 otherwise). If Stan is right, what will change (and how) when you include HOT as an additional independent variable in the regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Develop a sound regression model to estimate and predict the winning bid (Price) on the final contract for 2018, which has the characteristics below.\n",
    "<br>  The estimated cost is 10,000,000, of which 7,000,000 is due to fixed costs.\n",
    "<br>  The 4 contractors interested in the project are expected not to rig the auction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* FITTING A REGRESSION MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  Price   R-squared:                       0.968\n",
      "Model:                            OLS   Adj. R-squared:                  0.967\n",
      "Method:                 Least Squares   F-statistic:                     973.5\n",
      "Date:                Mon, 14 Jan 2019   Prob (F-statistic):           9.44e-95\n",
      "Time:                        15:07:41   Log-Likelihood:                -931.11\n",
      "No. Observations:                 133   AIC:                             1872.\n",
      "Df Residuals:                     128   BIC:                             1887.\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     93.9664     64.099      1.466      0.145     -32.864     220.796\n",
      "FairPr         0.8515      0.077     11.032      0.000       0.699       1.004\n",
      "Bidders      -17.3139      9.677     -1.789      0.076     -36.462       1.834\n",
      "Rigged        88.1078     59.666      1.477      0.142     -29.952     206.167\n",
      "FxCost         0.1060      0.124      0.855      0.394      -0.139       0.351\n",
      "==============================================================================\n",
      "Omnibus:                      112.239   Durbin-Watson:                   2.030\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2920.016\n",
      "Skew:                          -2.500   Prob(JB):                         0.00\n",
      "Kurtosis:                      25.403   Cond. No.                     7.52e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 7.52e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "results2 = smf.ols('Price ~ FairPr + Bidders + Rigged + FxCost', data=df).fit()\n",
    "print(results2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  Price   R-squared:                       0.968\n",
      "Model:                            OLS   Adj. R-squared:                  0.967\n",
      "Method:                 Least Squares   F-statistic:                     1301.\n",
      "Date:                Mon, 14 Jan 2019   Prob (F-statistic):           3.47e-96\n",
      "Time:                        15:08:07   Log-Likelihood:                -931.49\n",
      "No. Observations:                 133   AIC:                             1871.\n",
      "Df Residuals:                     129   BIC:                             1883.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     78.4696     61.421      1.278      0.204     -43.053     199.992\n",
      "FairPr         0.9162      0.015     59.603      0.000       0.886       0.947\n",
      "Bidders      -17.1260      9.665     -1.772      0.079     -36.248       1.996\n",
      "Rigged        90.7143     59.526      1.524      0.130     -27.060     208.488\n",
      "==============================================================================\n",
      "Omnibus:                      111.997   Durbin-Watson:                   2.044\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3019.018\n",
      "Skew:                          -2.476   Prob(JB):                         0.00\n",
      "Kurtosis:                      25.809   Cond. No.                     6.39e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 6.39e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "results3 = smf.ols('Price ~ FairPr + Bidders + Rigged', data=df).fit()\n",
    "print(results3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>-23.289104</td>\n",
       "      <td>180.228365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FairPr</th>\n",
       "      <td>0.890713</td>\n",
       "      <td>0.941646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bidders</th>\n",
       "      <td>-33.137839</td>\n",
       "      <td>-1.114195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rigged</th>\n",
       "      <td>-7.905811</td>\n",
       "      <td>189.334474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0           1\n",
       "Intercept -23.289104  180.228365\n",
       "FairPr      0.890713    0.941646\n",
       "Bidders   -33.137839   -1.114195\n",
       "Rigged     -7.905811  189.334474"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results3.conf_int(alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* MULTICOLLINEARITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_1 = df[['FairPr', 'Bidders', 'Rigged']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('FairPr', 1.6123719489065504),\n",
       " ('Bidders', 1.6841488442073644),\n",
       " ('Rigged', 1.0739000919206745)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vif = [variance_inflation_factor(X_1.values, i) for i in range(X_1.shape[1])]\n",
    "lzip(X_1.columns, vif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* FUNCTIONAL FORM OF A MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'statsmodels.stats.contrast.ContrastResults'>\n",
       "<F test: F=array([[1286.27748349]]), p=7.24548266486042e-103, df_denom=129, df_num=4>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = ['t value', 'p value']\n",
    "test = reset_ramsey(results3)\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ramsey RESET Test\n",
    "<br> H_0: correct specification of the model\n",
    "<br> H_1: the model suffers from misspecification\n",
    "<br> RESET = 7.24548266486042e-103 < 0.05 => there is a reason to reject null hyphothesis\n",
    "<br> The model suffers from misspecification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* NORMALITY OF THE RESIDUALS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jarque-Bera Test\n",
    "<br> H_0: residuals have a normal distribution\n",
    "<br> H_1: residuals do not have a normal distribution\n",
    "<br> JB = 0.00 > 0.05 => there is a reason to reject null hyphothesis\n",
    "<br> Residuals do not have a normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAExlJREFUeJzt3X2wJXV95/H3RwbE9QmQC5lAxoGS\nqCRbYrxhMUQrgrpGk4C7YkxMnDVspipPa9bEzSRUpbTyBHnSPFhSo7iOhkQIK8v4EBUnoJUqRGZ4\nRlCQoBJmmdEEheiio9/80T3heL0P547T59x7f+9X1anT/Tvdp78/Dmc+t7tP/zpVhSSpXY+adgGS\npOkyCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNWzftAsZx9NFH18aNG6ddhiSt\nKrt27fpCVc0stdyqCIKNGzeyc+fOaZchSatKks+Os5yHhiSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQ\nSFLjDAJJapxBIEmNMwgkqXGr4spiSSvHxi3vn9q27zn/JVPb9lrmHoEkNc4gkKTGDRoESY5IclmS\nO5LcnuTZSY5KcmWSO/vnI4esQZK0uKH3CP4M+GBVPQ14BnA7sAXYUVUnATv6eUnSlAwWBEmeADwX\nuAigqr5WVQ8AZwHb+sW2AWcPVYMkaWlD/mroRGAv8L+TPAPYBbwGOLaqdgNU1e4kx8y3cpLNwGaA\nDRs2DFimtDpN89c7WluGPDS0DvgB4C1V9UzgX1nGYaCq2lpVs1U1OzOz5A12JEkHaMgguBe4t6qu\n7ecvowuG+5OsB+if9wxYgyRpCYMFQVX9P+DzSZ7aN50JfBLYDmzq2zYBVwxVgyRpaUNfWfwrwMVJ\nDgPuBl5NFz6XJjkX+BxwzsA1SJIWMWgQVNWNwOw8L5055HYlSePzymJJapxBIEmNMwgkqXEGgSQ1\nziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMM\nAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLj1g355knuAR4EvgHsq6rZJEcBlwAb\ngXuAl1fVvwxZhyRpYZPYI3heVZ1SVbP9/BZgR1WdBOzo5yVJUzKNQ0NnAdv66W3A2VOoQZLUGzoI\nCvhwkl1JNvdtx1bVboD++ZiBa5AkLWLQcwTA6VV1X5JjgCuT3DHuin1wbAbYsGHDUPVJUvMG3SOo\nqvv65z3A5cCpwP1J1gP0z3sWWHdrVc1W1ezMzMyQZUpS0wYLgiSPTfL4/dPAC4Fbge3Apn6xTcAV\nQ9UgSVrakIeGjgUuT7J/O39dVR9Mch1waZJzgc8B5wxYgyRpCYMFQVXdDTxjnvYvAmcOtV1J0vJ4\nZbEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQ\nSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEk\nNW7wIEhySJIbkryvnz8hybVJ7kxySZLDhq5BkrSwSewRvAa4fWT+AuCNVXUS8C/AuROoQZK0gEGD\nIMnxwEuAt/XzAc4ALusX2QacPWQNkqTFDb1H8CbgfwHf7OefBDxQVfv6+XuB4+ZbMcnmJDuT7Ny7\nd+/AZUpSuwYLgiQ/Buypql2jzfMsWvOtX1Vbq2q2qmZnZmYGqVGSBOsGfO/TgZ9I8mLgcOAJdHsI\nRyRZ1+8VHA/cN2ANkqQlDLZHUFW/WVXHV9VG4BXA31fVK4GrgJf1i20CrhiqBknS0qZxHcFvAK9N\nchfdOYOLplCDJKk35KGhf1dVVwNX99N3A6dOYruSpKV5ZbEkNc4gkKTGGQSS1DiDQJIaZxBIUuMM\nAklq3FhBkOT0cdokSavPuHsEfzFmmyRplVn0grIkzwZ+CJhJ8tqRl54AHDJkYZKkyVjqyuLDgMf1\nyz1+pP3LPDJekCRpFVs0CKrqo8BHk7yjqj47oZokSRM07lhDj06yFdg4uk5VnTFEUZKkyRk3CP4W\nuJDulpPfGK4cSdKkjRsE+6rqLYNWIkmainF/PvreJL+YZH2So/Y/Bq1MkjQR4+4RbOqfXzfSVsCJ\nB7ccSdKkjRUEVXXC0IVIkqZjrCBI8qr52qvqnQe3HEnSpI17aOgHR6YPB84ErgcMAkla5cY9NPQr\no/NJngi8a5CKJEkTdaDDUH8FOOlgFiJJmo5xzxG8l+5XQtANNvd04NKhipIkTc645wj+eGR6H/DZ\nqrp3gHokSRM21qGhfvC5O+hGID0S+NqQRUmSJmfcO5S9HPgEcA7wcuDaJIsOQ53k8CSfSHJTktuS\nvKFvPyHJtUnuTHJJksO+005Ikg7cuIeGzgN+sKr2ACSZAT4CXLbIOg8DZ1TVQ0kOBf4hyd8BrwXe\nWFXvTnIhcC7gOEaSNCXj/mroUftDoPfFpdatzkP97KH9o4AzeCRAtgFnj1+uJOlgG3eP4INJPgT8\nTT//k8AHllopySHALuApwJuBzwAPVNW+fpF7geOWVbEk6aBa6p7FTwGOrarXJfkvwA8DAa4BLl7q\nzavqG8ApSY4ALqf72em3LbbAtjcDmwE2bNiw1KYkSQdoqUNDbwIeBKiq91TVa6vqf9LtDbxp3I1U\n1QPA1cBpwBFJ9gfQ8cB9C6yztapmq2p2ZmZm3E1JkpZpqSDYWFU3z22sqp10t61cUJKZfk+AJI8B\nng/cDlzFIze+3wRcscyaJUkH0VLnCA5f5LXHLLHuemBbf57gUcClVfW+JJ8E3p3kd4EbgIvGrlaS\ndNAtFQTXJfn5qnrraGOSc+lOAi+o35N45jztdwOnLrdQSdIwlgqCXwUuT/JKHvmHfxY4DHjpkIVJ\nkiZj0SCoqvuBH0ryPOD7++b3V9XfD16ZJGkixr0fwVV0J3klSWvMgd6PQJK0RhgEktQ4g0CSGmcQ\nSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEk\nNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklq3GBBkOR7klyV5PYktyV5Td9+VJIrk9zZPx85VA2SpKUN\nuUewD/i1qno6cBrwS0lOBrYAO6rqJGBHPy9JmpLBgqCqdlfV9f30g8DtwHHAWcC2frFtwNlD1SBJ\nWtpEzhEk2Qg8E7gWOLaqdkMXFsAxk6hBkjS/wYMgyeOA/wP8alV9eRnrbU6yM8nOvXv3DlegJDVu\n0CBIcihdCFxcVe/pm+9Psr5/fT2wZ751q2prVc1W1ezMzMyQZUpS04b81VCAi4Dbq+pPR17aDmzq\npzcBVwxVgyRpaesGfO/TgZ8FbklyY9/2W8D5wKVJzgU+B5wzYA2SpCUMFgRV9Q9AFnj5zKG2K0la\nHq8slqTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLj\nDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4g\nkKTGDRYESd6eZE+SW0fajkpyZZI7++cjh9q+JGk8Q+4RvAN40Zy2LcCOqjoJ2NHPS5KmaLAgqKqP\nAf88p/ksYFs/vQ04e6jtS5LGM+lzBMdW1W6A/vmYhRZMsjnJziQ79+7dO7ECJak1K/ZkcVVtrarZ\nqpqdmZmZdjmStGZNOgjuT7IeoH/eM+HtS5LmmHQQbAc29dObgCsmvH1J0hxD/nz0b4BrgKcmuTfJ\nucD5wAuS3Am8oJ+XJE3RuqHeuKp+aoGXzhxqm5Kk5VuxJ4slSZNhEEhS4wwCSWqcQSBJjTMIJKlx\nBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklq3GBjDUnSWrFxy/unst17zn/JRLbjHoEkNc4gkKTG\nGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOK4u1Jqz1Kz/VmdbnvNa5RyBJjTMIJKlx\nUzk0lORFwJ8BhwBvq6rzh9qWhww0JA9VaC2Y+B5BkkOANwM/CpwM/FSSkyddhySpM41DQ6cCd1XV\n3VX1NeDdwFlTqEOSxHSC4Djg8yPz9/ZtkqQpmMY5gszTVt+2ULIZ2NzPPpTkU2O+/9HAFw6wtoMm\nFwzytiuibwNZq31bq/2Ctdu3FdOvg/DvyJPHWWgaQXAv8D0j88cD981dqKq2AluX++ZJdlbV7IGX\nt3LZt9VnrfYL1m7f1mq/FjONQ0PXASclOSHJYcArgO1TqEOSxBT2CKpqX5JfBj5E9/PRt1fVbZOu\nQ5LUmcp1BFX1AeADA739sg8nrSL2bfVZq/2Ctdu3tdqvBaXq287TSpIa4hATktS4VRcESf4oyR1J\nbk5yeZIjRl77zSR3JflUkv880v6ivu2uJFtG2k9Icm2SO5Nc0p+8nook5yS5Lck3k8yOtG9M8tUk\nN/aPC0dee1aSW/p+/XmS9O1HJbmy79eVSY6cRp9G6py3b/1rq/YzmyvJ65P808hn9eKR15bVz5Vs\nNdY8V5J7+u/OjUl29m3zfm/S+fO+vzcn+YHpVj+AqlpVD+CFwLp++gLggn76ZOAm4NHACcBn6E5G\nH9JPnwgc1i9zcr/OpcAr+ukLgV+YYr+eDjwVuBqYHWnfCNy6wDqfAJ5Nd23G3wE/2rf/IbCln96y\n/7/RCuzbqv7M5unn64Ffn6d92f1cqY/VWPMC/bgHOHpO27zfG+DF/fcrwGnAtdOu/2A/Vt0eQVV9\nuKr29bMfp7sOAbphKt5dVQ9X1T8Cd9ENZzHvkBb9X89nAJf1628Dzp5UP+aqqturatyL5kiyHnhC\nVV1T3f+t7+SR+s+i6w9MuV+waN9W9We2DMvq5xTrHMdqrHlcC31vzgLeWZ2PA0f03781Y9UFwRw/\nR5fUsPDQFQu1Pwl4YCRUVvJQFyckuSHJR5M8p287jq7m/UbrP7aqdgP0z8dMrtRlWYuf2S/3hw/e\nPnJIbrn9XMlWY83zKeDDSXb1oxjAwt+btdLnBa3IO5Ql+QjwXfO8dF5VXdEvcx6wD7h4/2rzLF/M\nH3a1yPKDGadf89gNbKiqLyZ5FvB/k3wfU6h/MQfYtxX/mc21WD+BtwC/09f0O8Cf0P2xstx+rmRT\n/wwOktOr6r4kxwBXJrljkWXXSp8XtCKDoKqev9jrSTYBPwac2R8WgcWHrpiv/Qt0u3jr+r8w5x3q\n4mBaql8LrPMw8HA/vSvJZ4Dvpevv8SOLjtZ/f5L1VbW734Xd851VPlady+4bq+Azm2vcfiZ5K/C+\nfna5/VzJxhoiZqWrqvv65z1JLqc75LXQ92ZN9Hkxq+7QULqb2vwG8BNV9ZWRl7YDr0jy6CQnACfR\nnUydd0iLPkCuAl7Wr78JWOgv16lJMpPuHg4kOZGuX3f3u64PJjmtP3b+Kh6pfztdf2CF9qu3pj6z\nOceNXwrc2k8vq5+TrPkArMaav0WSxyZ5/P5puh+g3MrC35vtwKv6Xw+dBnxp/yGkNWPaZ6uX+6A7\n0fZ54Mb+ceHIa+fR/aLhU/S/oKlHzvp/un/tvJH2E+m+kHcBfws8eor9eindXx4PA/cDH+rb/ytw\nG92vM64HfnxknVm6/4E/A/wlj1wg+CRgB3Bn/3zUlD+zefu22j+zefr5LuAW4Ga6fzzWH2g/V/Jj\nNdY8p/4T++/TTf1367y+fd7vDd2hoTf3/b2FkV++rZWHVxZLUuNW3aEhSdLBZRBIUuMMAklqnEEg\nSY0zCCSpcQaB1rwk3+hHmbw1yXszMmLtMt/nbUlOnqf9vyX5y++gvocOdF3pYDAI1IKvVtUpVfX9\nwD8Dv3Qgb1JV/72qPnlwS5OmzyBQa65hZMCwJK9Lcl0/UNwb+rbHJnl/kpv6vYif7NuvTn8/hSSv\nTvLpJB8FTh95v3ckednI/EP98+OS7EhyfT8O/reN2JlkfZKPjey9PGfuMtIQVuRYQ9IQ+qE6zgQu\n6udfSDfcw6l0V49uT/JcYAa4r6pe0i/3xDnvsx54A/As4Et0w17csMTm/z/w0qr6cpKjgY8n2T9s\nxn4/TXfV9e/1tf6H76jD0pjcI1ALHpPkRuCLwFHAlX37C/vHDXTDdzyNLhhuAZ6f5IIkz6mqL815\nv/8EXF1Ve6sbk/+SMWoI8PtJbgY+QrdXcuycZa4DXp3k9cB/rKoHl9lP6YAYBGrBV6vqFODJdHfV\n2n+OIMAf9OcPTqmqp1TVRVX1abq/9m8B/iDJb8/znguNzbKP/nvVDwa4/1aar6Tb03hWX8v9wOHf\n8oZVHwOeC/wT8K4krzqw7krLYxCoGf1f9v8D+PUkhwIfAn4uyeMAkhyX5Jgk3w18par+CvhjYO49\naq8FfiTJk/r3OWfktXvoQgS6O1sd2k8/EdhTVV9P8jy6UPoWSZ7cL/NWusNXa+/euFqRPEegplTV\nDUluorvv8buSPB24pvvjnYeAnwGeAvxRkm8CXwd+Yc577O4P31xDd+Og6+nu5QvwVuCKJJ+gG8Hy\nX/v2i4H3prtR+o3AfDdC+RHgdUm+3tfiHoEmwtFHJalxHhqSpMYZBJLUOINAkhpnEEhS4wwCSWqc\nQSBJjTMIJKlxBoEkNe7fANeXWxE6t496AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(results3.resid)\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Residuals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* HETEROSKEDASTICITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Lagrange multiplier statistic', 47.30678503749735),\n",
       " ('p-value', 2.990676834816012e-10),\n",
       " ('f-value', 23.73807258255512),\n",
       " ('f p-value', 2.677834124908958e-12)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = ['Lagrange multiplier statistic', 'p-value',\n",
    "        'f-value', 'f p-value']\n",
    "test = sms.het_breuschpagan(results3.resid, results3.model.exog)\n",
    "lzip(name, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Breush-Pagan test\n",
    "<br> H_0: homoskedasticity\n",
    "<br> H_1: heteroskedasticity\n",
    "BP = 2.990676834816012e-10 < 0.05 => there is a reason to reject null hyphothesis\n",
    "<br> The problem of heteroskedasticity occures in this model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SOME COMMMENT WHY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* FITTING A REGRESSION MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               logPrice   R-squared:                       0.849\n",
      "Model:                            OLS   Adj. R-squared:                  0.844\n",
      "Method:                 Least Squares   F-statistic:                     179.5\n",
      "Date:                Mon, 14 Jan 2019   Prob (F-statistic):           1.78e-51\n",
      "Time:                        15:50:47   Log-Likelihood:                -102.96\n",
      "No. Observations:                 133   AIC:                             215.9\n",
      "Df Residuals:                     128   BIC:                             230.4\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      3.4241      0.166     20.672      0.000       3.096       3.752\n",
      "FairPr         0.0002   4.47e-05      4.654      0.000       0.000       0.000\n",
      "Bidders       -0.0235      0.020     -1.172      0.243      -0.063       0.016\n",
      "Rigged         0.1570      0.121      1.303      0.195      -0.081       0.396\n",
      "logFxCost      0.5252      0.040     13.283      0.000       0.447       0.603\n",
      "==============================================================================\n",
      "Omnibus:                        5.157   Durbin-Watson:                   1.086\n",
      "Prob(Omnibus):                  0.076   Jarque-Bera (JB):                7.402\n",
      "Skew:                          -0.055   Prob(JB):                       0.0247\n",
      "Kurtosis:                       4.151   Cond. No.                     7.28e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 7.28e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "df['logPrice']=np.log(df['Price'])\n",
    "df['logFxCost']=np.log(df['FxCost'])\n",
    "results4 = smf.ols('logPrice ~ FairPr + Bidders + Rigged + logFxCost', data=df).fit()\n",
    "print(results4.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               logPrice   R-squared:                       0.847\n",
      "Model:                            OLS   Adj. R-squared:                  0.844\n",
      "Method:                 Least Squares   F-statistic:                     238.2\n",
      "Date:                Mon, 14 Jan 2019   Prob (F-statistic):           2.09e-52\n",
      "Time:                        15:52:50   Log-Likelihood:                -103.67\n",
      "No. Observations:                 133   AIC:                             215.3\n",
      "Df Residuals:                     129   BIC:                             226.9\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      3.3489      0.153     21.898      0.000       3.046       3.651\n",
      "FairPr         0.0002   4.47e-05      4.677      0.000       0.000       0.000\n",
      "Rigged         0.2237      0.106      2.102      0.038       0.013       0.434\n",
      "logFxCost      0.5113      0.038     13.537      0.000       0.437       0.586\n",
      "==============================================================================\n",
      "Omnibus:                        5.085   Durbin-Watson:                   1.110\n",
      "Prob(Omnibus):                  0.079   Jarque-Bera (JB):                6.857\n",
      "Skew:                          -0.119   Prob(JB):                       0.0324\n",
      "Kurtosis:                       4.086   Cond. No.                     6.59e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 6.59e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "results4 = smf.ols('logPrice ~ FairPr + Rigged + logFxCost', data=df).fit()\n",
    "print(results4.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'OLSResults' object has no attribute 'coef'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-24259fefc944>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/statsmodels/base/wrapper.py\u001b[0m in \u001b[0;36m__getattribute__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mhow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_attrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'OLSResults' object has no attribute 'coef'"
     ]
    }
   ],
   "source": [
    "results4.coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>FairPr</th>\n",
       "      <th>Ratio</th>\n",
       "      <th>Bidders</th>\n",
       "      <th>Rigged</th>\n",
       "      <th>Length</th>\n",
       "      <th>FxCost</th>\n",
       "      <th>Days</th>\n",
       "      <th>logPrice</th>\n",
       "      <th>logFxCost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1115</td>\n",
       "      <td>1149</td>\n",
       "      <td>0.970409</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>561.861</td>\n",
       "      <td>250</td>\n",
       "      <td>7.016610</td>\n",
       "      <td>6.331254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>62</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>62.000</td>\n",
       "      <td>60</td>\n",
       "      <td>3.828641</td>\n",
       "      <td>4.127134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>240</td>\n",
       "      <td>195</td>\n",
       "      <td>1.230769</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>85.215</td>\n",
       "      <td>65</td>\n",
       "      <td>5.480639</td>\n",
       "      <td>4.445177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>57</td>\n",
       "      <td>1.122807</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>16.074</td>\n",
       "      <td>70</td>\n",
       "      <td>4.158883</td>\n",
       "      <td>2.777203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>170</td>\n",
       "      <td>187</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>80.784</td>\n",
       "      <td>100</td>\n",
       "      <td>5.135798</td>\n",
       "      <td>4.391779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Price  FairPr     Ratio  Bidders  Rigged  Length   FxCost  Days  logPrice  \\\n",
       "0   1115    1149  0.970409        9       0     0.1  561.861   250  7.016610   \n",
       "1     46      62  0.741935        8       0     0.1   62.000    60  3.828641   \n",
       "2    240     195  1.230769        3       1     0.2   85.215    65  5.480639   \n",
       "3     64      57  1.122807        2       1     0.2   16.074    70  4.158883   \n",
       "4    170     187  0.909091        3       0     0.2   80.784   100  5.135798   \n",
       "\n",
       "   logFxCost  \n",
       "0   6.331254  \n",
       "1   4.127134  \n",
       "2   4.445177  \n",
       "3   2.777203  \n",
       "4   4.391779  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>3.095513</td>\n",
       "      <td>3.602250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FairPr</th>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rigged</th>\n",
       "      <td>0.047376</td>\n",
       "      <td>0.399991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logFxCost</th>\n",
       "      <td>0.448709</td>\n",
       "      <td>0.573853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0         1\n",
       "Intercept  3.095513  3.602250\n",
       "FairPr     0.000135  0.000283\n",
       "Rigged     0.047376  0.399991\n",
       "logFxCost  0.448709  0.573853"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results4.conf_int(alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* MULTICOLLINEARITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_2 = df[['FairPr', 'Rigged', 'logFxCost']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('FairPr', 2.4736953694751724),\n",
       " ('Rigged', 1.391865859097974),\n",
       " ('logFxCost', 3.0491460773198384)]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vif = [variance_inflation_factor(X_2.values, i) for i in range(X_2.shape[1])]\n",
    "lzip(X_2.columns, vif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* FUNCTIONAL FORM OF A MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'statsmodels.stats.contrast.ContrastResults'>\n",
       "<F test: F=array([[24.02984396]]), p=9.899838124925551e-15, df_denom=124, df_num=4>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = ['t value', 'p value']\n",
    "test = reset_ramsey(results4)\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ramsey RESET Test\n",
    "<br> H_0: correct specification of the model\n",
    "<br> H_1: the model suffers from misspecification\n",
    "<br> RESET = 9.899838124925551e-15 < 0.05 => there is a reason to reject null hyphothesis\n",
    "<br> The model suffers from misspecification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* NORMALITY OF THE RESIDUALS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jarque-Bera Test\n",
    "<br> H_0: residuals have a normal distribution\n",
    "<br> H_1: residuals do not have a normal distribution\n",
    "<br> JB = 0.0324 < 0.05 => there is a reason to reject null hyphothesis\n",
    "<br> Residuals do not have a normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB8KKTOrVQd4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(results4.resid)\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Residuals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Assumption of Normal Distribution of Residuals does not have to be met. According to Gauss-Markov Theorem Least Squares Regression is the BLUE estimator regardless of it. A normal distribution is only used to show that the estimator is also the Maximum Likelihood Estimator. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* HETEROSKEDASTICITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Lagrange multiplier statistic', 34.38240491012998),\n",
       " ('p-value', 6.220381824979775e-07),\n",
       " ('f-value', 11.156598942830794),\n",
       " ('f p-value', 8.52566706416611e-08)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = ['Lagrange multiplier statistic', 'p-value',\n",
    "        'f-value', 'f p-value']\n",
    "test = sms.het_breuschpagan(results4.resid, results4.model.exog)\n",
    "lzip(name, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Breush-Pagan test\n",
    "<br> H_0: homoskedasticity\n",
    "<br> H_1: heteroskedasticity\n",
    "BP = 6.220381824979775e-07 < 0.05 => there is a reason to reject null hyphothesis\n",
    "<br> The problem of heteroskedasticity occures in this model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MODEL 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the heteroskedasticity of residuals the model was re-estimated using the Weighted Least Squares Method that is a special case of the Generalized Least Squares Method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "variance of residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "1/sqrt(exp(auxilary.lm$fitted.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = 1/sqrt(exp(auxilary.lm$fitted.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            WLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               logPrice   R-squared:                       0.966\n",
      "Model:                            WLS   Adj. R-squared:                  0.965\n",
      "Method:                 Least Squares   F-statistic:                     1215.\n",
      "Date:                Mon, 14 Jan 2019   Prob (F-statistic):           7.14e-95\n",
      "Time:                        16:45:30   Log-Likelihood:                -206.82\n",
      "No. Observations:                 133   AIC:                             419.6\n",
      "Df Residuals:                     130   BIC:                             428.3\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "FairPr        -0.0003   8.16e-05     -3.884      0.000      -0.000      -0.000\n",
      "Rigged         0.5561      0.228      2.440      0.016       0.105       1.007\n",
      "logFxCost      1.2600      0.035     36.291      0.000       1.191       1.329\n",
      "==============================================================================\n",
      "Omnibus:                       35.878   Durbin-Watson:                   1.872\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               62.980\n",
      "Skew:                           1.241   Prob(JB):                     2.11e-14\n",
      "Kurtosis:                       5.281   Cond. No.                     4.41e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.41e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "nsample = 133\n",
    "w = np.ones(nsample)\n",
    "y = df['logPrice']\n",
    "x = df[['FairPr', 'Rigged', 'logFxCost']]\n",
    "mod_wls = smf.WLS(y, x, data=df, weights=1./w)\n",
    "res_wls = mod_wls.fit()\n",
    "print(res_wls.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Write down the estimated regression equation and explain how you came to choose it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Give a point estimate for the winning bid and provide an interval that will contain the winning bid with 90% confidence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) How confident are you that in this project the winning bid will come in under budget (so that Bob will earn his bonus)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## MODEL 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ODOT has a road reconstruction project that is in the early planning phase. Just before putting the job up for auction, it is learnt that building an additional pedestrian bridge will be necessary as part of the project. This change will not affect the duration of the job or the length of the road, but it will increase fixed costs (FxCost) by 15% and overall estimated costs (FairPr) by 5%.\n",
    "<BR> ODOT hasnt put the project up for bidding yet, and your goal is to estimate the percentage increase in the winning bid (the Price of the contract) that will ultimately result from the change in projected costs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) What regression would you use to estimate the increase in Price? Write down the estimated regression equation, and explain how you arrived at that regression.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Using your regression in part (a), what is your estimate for the percentage increase in the Price of this contract?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
